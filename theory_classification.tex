\subsection{Teoría de Clasificación}

\begin{definition}
Sea $\mathcal{X} \subseteq \mathbb{R}^p$ el espacio de características y $\mathcal{Y} = \{1,\ldots,K\}$ el conjunto de etiquetas de clase. Un clasificador es una función $\hat{G}: \mathcal{X} \to \mathcal{Y}$ que asigna una etiqueta de clase a cada punto del espacio de características.
\end{definition}

El objetivo de la clasificación es hallar un clasificador que prediga correctamente la etiqueta de clase verdadera $Y \in \mathcal{Y}$ para nuevas observaciones $X \in \mathcal{X}$. Para evaluar y comparar distintos clasificadores, necesitamos una manera formal de medir su desempeño. Esto nos lleva al concepto de error de predicción esperado.

\begin{definition}
Sea $X \in \mathbb{R}^p$ un vector aleatorio de características, $Y \in \{1,\ldots,K\}$ una variable aleatoria categórica que representa la etiqueta de clase, y $\hat{G}: \mathbb{R}^p \to \{1,\ldots,K\}$ un clasificador. Sea $L: \{1,\ldots,K\} \times \{1,\ldots,K\} \to \mathbb{R}$ una función pérdida que mide el costo de una clasificación incorrecta.

El Error de Predicción Esperado (EPE) del clasificador $\hat{G}(X)$ se define como la esperanza de la función de pérdida $L(Y, \hat{G}(X))$ sobre la distribución conjunta de $X$ e $Y$:
\[
\text{EPE}(\hat{G}) = \mathbb{E}[L(Y, \hat{G}(X))]
\]
\end{definition}

La elección de la función de pérdida es crucial para medir el rendimiento de un clasificador. Diferentes funciones de pérdida pueden llevar a clasificadores óptimos distintos. En esta sección, nos enfocaremos en la función de pérdida cero-uno, que asigna una penalización de $1$ por cada mala clasificación y $0$ por una clasificación correcta.

\begin{definition}
La función de pérdida cero-uno se define como:
\[
L(y, k) = \begin{cases}
0 & \text{si } y = k \\
1 & \text{si } y \neq k
\end{cases}
\]
\end{definition}

Estamos interesados en encontrar el clasificador que minimice el error de predicción esperado bajo la función de pérdida cero-uno, que, intuitivamente, es el clasificador que asigna cada entrada a la clase con la mayor probabilidad a posteriori.

\begin{theorem}
Sea $X$ un vector aleatorio con función de densidad de probabilidad $f_X: \mathbb{R}^p \to \mathbb{R}_{\geq 0}$, y sea $Y$ una variable aleatoria discreta que toma valores en $\{1,\ldots,K\}$. Supongamos que las funciones de densidad de probabilidad condicional $f_{X|Y}(x|y)$ existen para todo $y \in \{1,\ldots,K\}$.

El clasificador que minimiza el error de predicción esperado (EPE) bajo la función de pérdida cero-uno asigna cada entrada $x$ a la clase con la mayor probabilidad a posteriori $\mathbb{P}(Y = k \mid X = x)$.
\[
\hat{G}(x) = \arg\max_{k=1}^K \mathbb{P}(Y = k \mid X = x)
\]
\end{theorem}

\begin{proof}
El error de predicción esperado del clasificador $\hat{G}(X)$ se puede escribir como:
\begin{align*}
\mathbb{E}[L(Y, \hat{G}(X))] & = \sum_{y=1}^K \int_{\mathbb{R}^{p}} L(y, \hat{G}(x)) f_{X|Y}(x|y)\mathbb{P}(Y=y)\, dx \\
& = \int_{\mathbb{R}^{p}} \left( \sum_{y=1}^K L(y, \hat{G}(x)) \mathbb{P}(Y = y \mid X = x) \right) f_X(x) \, dx \\
& = \mathbb{E}_X\left[ \sum_{y=1}^K L(y, \hat{G}(X)) \mathbb{P}(Y = y \mid X) \right]
\end{align*}
donde usamos el teorema de Bayes y el teorema de la probabilidad total. Para minimizar esta esperanza, podemos minimizar punto a punto para cada valor de $x$:
\[
\hat{G}(x) = \arg\min_{k=1}^K \sum_{y=1}^K L(y, k) \mathbb{P}(Y = y \mid X = x)
\]
Usando la función de pérdida cero-uno:
\begin{align*}
\hat{G}(x) & = \arg\min_{k=1}^K \left(1 - \mathbb{P}(Y = k \mid X = x)\right) \\
& = \arg\max_{k=1}^K \mathbb{P}(Y = k \mid X = x)
\end{align*}
\end{proof}

Este resultado teórico se conoce como el clasificador óptimo de Bayes, y proporciona la base para desarrollar algoritmos de clasificación prácticos.

\begin{definition}
El clasificador óptimo de Bayes es el clasificador que asigna cada entrada $x$ a la clase $k$ que maximiza la probabilidad a posteriori $\mathbb{P}(Y = k \mid X = x)$:
\[
\hat{G}(x) = \arg\max_{k=1}^K \mathbb{P}(Y = k \mid X = x)
\]
\end{definition}
El clasificador óptimo de Bayes minimiza el error de predicción esperado y proporciona el mejor rendimiento de clasificación posible dadas las verdaderas distribuciones condicionales de las clases.
